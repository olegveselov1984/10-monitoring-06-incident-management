# 10-monitoring-06-incident-management

2018 October 21 22:52 UTC
Начало разделения сети (БД).Направление данных в западный Дата-центр.

2018 October 21 22:54 UTC
Мониторинг сообщает о сбоях в работе приложений.

2018 October 21 23:07 UTC
Блокировка развертывания БД.

2018 October 21 23:13 UTC
Специалисты выяснили, что несколько секунд записи данных не переданы в западный ДЦ.

2018 October 21 23:19 UTC
Оставнока работы Push запросов.

2018 October 22 00:05 UTC
Разработка плана действий. Решение о восстановления данных из резервной копии.

2018 October 22 00:41 UTC
Создание РК с последними актуальными данными.

2018 October 22 06:51 UTC
Частичное восставноление работоспособности.

2018 October 22 07:46 UTC
Информирование общественности о проводимых работах.

2018 October 22 11:12 UTC
Продолжение работ.

2018 October 22 13:15 UTC
Продолжение работ.

2018 October 22 16:24 UTC
Продолжение работ.

2018 October 22 16:45 UTC
Продолжение работ.

2018 October 22 23:03 UTC
Работы завершены


_________________________________________________________________________________________
https://disk.360.yandex.ru/d/L01z1xjJfBboew


Благодарим вас за выполнение домашнего задания по теме «Инцидент-менеджмент».
Краткое описание разделов (из презентации):
    • Краткое описание инцидента — краткая выжимка о инциденте.
    • Предшествующие события — что произошло перед инцидентом.
    • Причина инцидента — из-за чего возник инцидент.
    • Воздействие — на что повлиял инцидент.
    • Обнаружение — когда и как инцидент был обнаружен.
    • Реакция — кто ответил на инцидент, кто был привлечен, какие каналы коммуникации были задействованы.
    • Восстановление — описание действий по устранению инцидента и поведение системы.
    • Таймлайн — последовательное описание ключевых событий инцидента с указанием времени.
    • Последующие действия — что нужно предпринять, чтобы инцидент не повторялся.
Решение:

Раздел
	
Сбой системы GitHub 21 октября 2018
Краткое описание инцидента	После непродолжительной потери связи между сетевым узлом и датацентром нарушилась топология кластеров Оркестратора, что привело к деградированию системы
Предшествующие события	Плановые работы по замене вышедшего из строя 100G оптического оборудования в дата-центре на восточном побережье США
Причина инцидента	В результате временной потери связи кластеры MySQL перешли в "неожиданное" для Оркестратора состояние (только западные). 
Нормальное состояние:




Состояние после сбоя:



Воздействие	Отображение устаревшей и непоследовательной информации. Также в большинстве случаев не функционировали WebHook и сборка и публикация GitHub Pages.
Обнаружение	Инцидент был замечен дежурными инженерами через оповещения системы мониторинга.
Реакция	Группа реагирования провела минимизацию накопления сложности инцидента (отключила часть сервисов для минимизации изменений БД), после чего подключились к работе координатор и дополнительные разработчики из инженерной группы БД. Из-за приоритета целостности данных общее время восстановления составило 24 часа 11 минут.
Восстановление	Для исключения потери данных временно отключили часть сервисов для мининизации накопления изменений, после чего восстановили данные из резервных копий, а на них реплицировали накопленные. Далее вручную переконфигурировали топологию кластеров БД и включили деактивированный функционал. Завершающим этапом дождались отработки накопленных задач для чего даже потребовалось временно развернуть дополнительные реплики на чтение.



Таймлайн	21 октября 2018, 22:52 UTC - Нарушилась связь между сетевым узлом и основным дата-центром на восточном побережье США
21 октября 2018, 22:52 UTC - Оркестратор в основном дата-центре запустил процесс выбора нового лидера, в результате чего начал создавать топологию кластера БД на западе. После восстановления подключения приложения направили трафик по записи на новые основные сервера на западе. Таким образом на обоих серверах образовались данные, отсутствующие у другого и не получилось вернуть первичный сервер не восток
21 октября 2018, 22:54 UTC - Внутренние системы мониторинга начали генерировать оповещения о многочисленных сбоях в работе систем
21 октября 2018, 23:02 UTC - Инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в неожиданном состоянии - при запросе API Оркестратора отображалась топология репликации БД, содержащая только серверы из западного ЦОД.
21 октября 2018, 23:07 UTC - Группа реагирования вручную заблокировала внутренние средства развёртывания, чтобы предотвратить внесение дополнительных изменений в БД
21 октября 2018, 23:09 UTC - Группа реагирования установила жёлтый статус работоспособности сайта (статус активного инцидента)
21 октября 2018, 23:11 UTC - Координатор присоединился к работе и через две минуты принял решение изменить статус сайта на красный.
21 октября 2018, 23:13 UTC - К работе привлекли дополнительных разработчиков из инженерной группы БД, которые начали исследовать текущее состояние для определения необходимых действий для ручной перенастроийки БД
21 октября 2018, 23:19 UTC - В целях сохранности данных принято решение об остановке выполнения заданий, которые пишут метаданные типа пуш-запросов
22 октября 2018, 00:05 UTC - Инженеры из группы реагирования начали разрабатывать план устранения несогласованности данных и запустили процедуры отработки отказа для MySQL
22 октября 2018, 00:41 UTC - Инициирован процесс резервного копирования для всех затронутых кластеров MySQL. Одновременно нескольок групп инженеров изучали способы ускорения передачи и восстановления без дальнейшей деградации сайта или риска повреждения данных
22 октября 2018, 06:51 UTC - Несколько кластеров на востоке завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем
22 октября 2018, 07:46 UTC - Публикация информационного сообщение об инциденте
22 октября 2018, 11:12 UTC - Все первичные БД вновь переведены на Восток, но не смотря на возросшую производительность сайта некоторые данные всё ещё отставали на несколько часов из-за отложенных реплик
22 октября 2018, 13:15 UTC - Зафиксировано возрастание отставания репликации до согласованного состояния (время увеличивалось, а не уменьшалось). Начали подготовку дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья
22 октября 2018, 16:24 UTC - Завершена синхронизация реплик - возврат к исходной топологии. Устранинены проблемы задержки и доступности. Однако, красный статус сохранён, так как нужно ещё обработать накопленные данные.
22 октяюря 2018, 16:45 UTC - Включение всех дэактивированных функций. Корректировка TTL более 200000 истекших за время восстановления задач из более 5 миллионов.
22 октября 2018, 23:03 UTC - Все незавершённые события webhook и сборки Pages обработаны, а целостность и правильная работа всех систем подтверждена. Статус сайта изменён на зелёный
Последующие действия	Введена системная практика проверки сценариев сбоев, предже чем они возникнут в реальности (Chaos Engineering)





Пример из презентации
Раздел	Описание
Краткое описание инцидента	Около 2х часов ночи увеличилась утилизация ЦПУ на сервере. Вследствие этого часть сервисов стала недоступна.
Предшествующие события	Была установка патча 1.1 на сервис pretty
Причина инцидента	В патче 1.1 был допущен баг, в котором происходила многократная повторяющаяся запись на диск файлов.
Воздействие	Также на сервере с сервисом pretty был сервис корзины интернет магазина. Заказ товаров был недоступен для 100% пользователей в течении 15 минут.
Обнаружение	Инцидент был замечен дежурным инженером. Затем были привлечены ответственные разработчики.
Реакция	Ответственные разработчики устранили инцидент за 15 минут.
Восстановление	Был установлен минорный патч 1.1.1, устраняющий данную проблему и система перешла к штатной работе. Нагрузка сервера упала сразу после установки патча, корзина стала доступна для заказов
Таймлайн	01:55 прилетел алёрт о утилизации ЦПУ
01:57 дежурный инженер проинформировал о сбое ответственные лица
02:00 была проведена инспекция кода последнего патча и найдена проблема
02:05 был сделан коммит, устраняющий проблему
02:09 прошла автоматическая сборка и выкатка сервиса pretty
02:10 система заработала в штатном режиме
Последующие действия	Была заведена задача в issue tracker (ZADCH-123) по добавлению дополнительных модульных тестов на узкое место кода.

